{
 "metadata": {
  "name": "13_nlp_on_gossip_blog"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "MTO On Blast: Using Python's Natural Language Toolkit to Model Gossip Blogs"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Using natural language models to identify endemic constructions in a Hip Hop Gossip Blog\n",
      "\n",
      "Robert Elwell\n",
      "@languagehacker\n",
      "https://github.com/relwell/MTO-ON-BLAST\n",
      "Wikia"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Light introduction to NLTK\n",
      "\n",
      "mediatakeout.com\n",
      "\n",
      "hip hop + nltk\n",
      "\n",
      "Looking for patterns\n",
      "\n",
      "Create a headline generator\n",
      "- Create headlines from a grammar\n",
      "- Context Free Grammar (rules how words work, chomsky)\n",
      "- A language model (statistical knowledge)\n",
      "\n",
      "CFGs\n",
      "- Parse tree\n",
      "- Part of speech tagging\n",
      "- noun phrase + verb phrase into sentence\n",
      "- Writing a mad lib and randomizing entries\n",
      "- Rules can be domain specific\n",
      "- Randomly pick values that meet a rule\n",
      "\n",
      "mto-cfg.py on github\n",
      "\n",
      "CFG drawbacks:\n",
      "- have to write rules\n",
      "- enumerate the vocab\n",
      "- everything seen before, not entertaining\n",
      "\n",
      "Language models:\n",
      "- Use probabilities\n",
      "- N-grams\n",
      "\n",
      "We use probabilities too!\n",
      "\n",
      "Tokens vs Types:\n",
      "- useful when talking about probabilities\n",
      "- each unique word in a text is a type\n",
      "- token is observed instance\n",
      "\n",
      "N-gram probabilities\n",
      "\n",
      "What do we need?\n",
      "- A lot of data\n",
      "- Interesting domain space\n",
      "- Methodology for accessing and sanitizing data\n",
      "\n",
      "Multipart problem:\n",
      "- Web scraping\n",
      "- Language modeling\n",
      "\n",
      "Analyzing Text: Tokenization and filtering\n",
      "- nltk.tokenize -> Sentences broken out\n",
      "- tokenize sentences into words too\n",
      "- remove stopwords\n",
      "\n",
      "Analyzing Text: Frequency\n",
      "- nltk.probability\n",
      "-- FreqDist gives most frequent tokens\n",
      "-- FreqDist.itmes()\n",
      "- Influences analysis\n",
      "\n",
      "Tokenize sentences\n",
      "- n-gram creation (bi-grams, tri-grams)\n",
      "\n",
      "Now look at freqdist to print out most popular tokens\n",
      "\n",
      "NLTK Text class\n",
      "- Usefule to explore corpus\n",
      "- has own language model (generate())\n",
      "- Use NgramModel class\n",
      "\n",
      "NLTK NgramModel Class\n",
      "- Give me an order of n-grams and an instance of text\n",
      "- Give probability estimator for smoothing\n",
      "-- Adds some randomness\n",
      "- Give me between 5-25 words\n",
      "\n",
      "Observations:\n",
      "- Sentences not totally grammatical\n",
      "- Get pretty regular headlines\n",
      "\n",
      "Conclusions:\n",
      "- nltk complex\n",
      "- "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}