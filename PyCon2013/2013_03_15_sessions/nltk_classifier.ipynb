{
 "metadata": {
  "name": "nltk_classifier"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Natural Language Toolkit: Interface to scikit-learn classifiers\n",
      "#\n",
      "# Author: Lars Buitinck <L.J.Buitinck@uva.nl>\n",
      "# URL: <http://www.nltk.org/>\n",
      "# For license information, see LICENSE.TXT\n",
      "\"\"\"\n",
      "scikit-learn (http://scikit-learn.org) is a machine learning library for\n",
      "Python, supporting most of the basic classification algorithms, including SVMs,\n",
      "Naive Bayes, logistic regression and decision trees.\n",
      "\n",
      "This package implement a wrapper around scikit-learn classifiers. To use this\n",
      "wrapper, construct a scikit-learn classifier, then use that to construct a\n",
      "SklearnClassifier. E.g., to wrap a linear SVM classifier with default settings,\n",
      "do\n",
      "\n",
      ">>> from sklearn.svm.sparse import LinearSVC\n",
      ">>> from nltk.classify.scikitlearn import SklearnClassifier\n",
      ">>> classif = SklearnClassifier(LinearSVC())\n",
      "\n",
      "The scikit-learn classifier may be arbitrarily complex. E.g., the following\n",
      "constructs and wraps a Naive Bayes estimator with tf-idf weighting and\n",
      "chi-square feature selection:\n",
      "\n",
      ">>> from sklearn.feature_extraction.text import TfidfTransformer\n",
      ">>> from sklearn.feature_selection import SelectKBest, chi2\n",
      ">>> from sklearn.naive_bayes import MultinomialNB\n",
      ">>> from sklearn.pipeline import Pipeline\n",
      ">>> pipeline = Pipeline([('tfidf', TfidfTransformer()),\n",
      "...                      ('chi2', SelectKBest(chi2, k=1000)),\n",
      "...                      ('nb', MultinomialNB())])\n",
      ">>> classif = SklearnClassifier(pipeline)\n",
      "\n",
      "(Such a classifier could be trained on word counts for text classification.)\n",
      "\"\"\"\n",
      "\n",
      "from nltk.classify.api import ClassifierI\n",
      "from nltk.probability import DictionaryProbDist\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except ImportError:\n",
      "    pass\n",
      "\n",
      "class SklearnClassifier(ClassifierI):\n",
      "    \"\"\"Wrapper for scikit-learn classifiers.\"\"\"\n",
      "\n",
      "    def __init__(self, estimator, dtype=float, sparse=True):\n",
      "        \"\"\"\n",
      "        :param estimator: scikit-learn classifier object.\n",
      "\n",
      "        :param dtype: data type used when building feature array.\n",
      "            scikit-learn estimators work exclusively on numeric data; use bool\n",
      "            when all features are binary.\n",
      "\n",
      "        :param sparse: Whether to use sparse matrices. The estimator must\n",
      "            support these; not all scikit-learn classifiers do. The default\n",
      "            value is True, since most NLP problems involve sparse feature sets.\n",
      "        :type sparse: boolean.\n",
      "        \"\"\"\n",
      "        self._clf = estimator\n",
      "        self._dtype = dtype\n",
      "        self._sparse = sparse\n",
      "\n",
      "    def __repr__(self):\n",
      "        return \"<SklearnClassifier(%r)>\" % self._clf\n",
      "\n",
      "    def batch_classify(self, featuresets):\n",
      "        X = self._convert(featuresets)\n",
      "        y = self._clf.predict(X)\n",
      "        return [self._index_label[int(yi)] for yi in y]\n",
      "\n",
      "    def batch_prob_classify(self, featuresets):\n",
      "        X = self._convert(featuresets)\n",
      "        y_proba = self._clf.predict_proba(X)\n",
      "        return [self._make_probdist(y_proba[i]) for i in xrange(len(y_proba))]\n",
      "\n",
      "    def labels(self):\n",
      "        return self._label_index.keys()\n",
      "\n",
      "    def train(self, labeled_featuresets):\n",
      "        \"\"\"\n",
      "        Train (fit) the scikit-learn estimator.\n",
      "\n",
      "        :param labeled_featuresets: A list of classified featuresets,\n",
      "            i.e., a list of tuples ``(featureset, label)``.\n",
      "        \"\"\"\n",
      "\n",
      "        self._feature_index = {}\n",
      "        self._index_label = []\n",
      "        self._label_index = {}\n",
      "\n",
      "        for fs, label in labeled_featuresets:\n",
      "            for f in fs.iterkeys():\n",
      "                if f not in self._feature_index:\n",
      "                    self._feature_index[f] = len(self._feature_index)\n",
      "            if label not in self._label_index:\n",
      "                self._index_label.append(label)\n",
      "                self._label_index[label] = len(self._label_index)\n",
      "\n",
      "        featuresets, labels = zip(*labeled_featuresets)\n",
      "        X = self._convert(featuresets)\n",
      "        y = np.array([self._label_index[l] for l in labels])\n",
      "\n",
      "        self._clf.fit(X, y)\n",
      "\n",
      "        return self\n",
      "\n",
      "    def _convert(self, featuresets):\n",
      "        if self._sparse:\n",
      "            return self._featuresets_to_coo(featuresets)\n",
      "        else:\n",
      "            return self._featuresets_to_array(featuresets)\n",
      "\n",
      "    def _featuresets_to_coo(self, featuresets):\n",
      "        \"\"\"Convert featuresets to sparse matrix (COO format).\"\"\"\n",
      "\n",
      "        i_ind = []\n",
      "        j_ind = []\n",
      "        values = []\n",
      "\n",
      "        for i, fs in enumerate(featuresets):\n",
      "            for f, v in fs.iteritems():\n",
      "                try:\n",
      "                    j = self._feature_index[f]\n",
      "                    i_ind.append(i)\n",
      "                    j_ind.append(j)\n",
      "                    values.append(self._dtype(v))\n",
      "                except KeyError:\n",
      "                    pass\n",
      "\n",
      "        shape = (i + 1, len(self._feature_index))\n",
      "        return coo_matrix((values, (i_ind, j_ind)), shape=shape, dtype=self._dtype)\n",
      "\n",
      "    def _featuresets_to_array(self, featuresets):\n",
      "        \"\"\"Convert featureset to Numpy array.\"\"\"\n",
      "\n",
      "        X = np.zeros((len(featuresets), len(self._feature_index)),\n",
      "                     dtype=self._dtype)\n",
      "\n",
      "        for i, fs in enumerate(featuresets):\n",
      "            for f, v in fs.iteritems():\n",
      "                try:\n",
      "                    X[i, self._feature_index[f]] = self._dtype(v)\n",
      "                except KeyError:    # feature not seen in training\n",
      "                    pass\n",
      "\n",
      "        return X\n",
      "\n",
      "    def _make_probdist(self, y_proba):\n",
      "        return DictionaryProbDist(dict((self._index_label[i], p)\n",
      "                                       for i, p in enumerate(y_proba)))\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from nltk.classify.util import names_demo, binary_names_demo_features\n",
      "    try:\n",
      "        from sklearn.linear_model.sparse import LogisticRegression\n",
      "    except ImportError:     # separate sparse LR to be removed in 0.12\n",
      "        from sklearn.linear_model import LogisticRegression\n",
      "    from sklearn.naive_bayes import BernoulliNB\n",
      "\n",
      "    print(\"scikit-learn Naive Bayes:\")\n",
      "    names_demo(SklearnClassifier(BernoulliNB(binarize=False), dtype=bool).train,\n",
      "               features=binary_names_demo_features)\n",
      "    print\n",
      "    print(\"scikit-learn logistic regression:\")\n",
      "    names_demo(SklearnClassifier(LogisticRegression(), dtype=np.float64).train,\n",
      "               features=binary_names_demo_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scikit-learn Naive Bayes:\n",
        "Training classifier...\n",
        "Testing classifier..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy: 0.7780"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Avg. log likelihood: -0.8051"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Unseen Names      P(Male)  P(Female)\n",
        "----------------------------------------\n",
        "  Octavius        *0.9912   0.0088\n",
        "  Thomasina        0.0118  *0.9882\n",
        "  Barnett         *0.8929   0.1071\n",
        "  Angelina         0.0001  *0.9999\n",
        "  Saunders        *0.9735   0.0265\n",
        "\n",
        "scikit-learn logistic regression:\n",
        "Training classifier...\n",
        "Testing classifier..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy: 0.8000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Avg. log likelihood: -0.5957"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Unseen Names      P(Male)  P(Female)\n",
        "----------------------------------------\n",
        "  Octavius        *0.9762   0.0238\n",
        "  Thomasina        0.0342  *0.9658\n",
        "  Barnett         *0.6842   0.3158\n",
        "  Angelina         0.0037  *0.9963\n",
        "  Saunders        *0.8489   0.1511\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print binary_names_demo_features()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "binary_names_demo_features() takes exactly 1 argument (0 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-14f4b68258de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mbinary_names_demo_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: binary_names_demo_features() takes exactly 1 argument (0 given)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}