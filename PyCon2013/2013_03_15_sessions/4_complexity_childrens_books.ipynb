{
 "metadata": {
  "name": "4_complexity_childrens_books"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Measuring and modeling the complexity of children's books"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Jeff Elmore\n",
      "@enzondio\n",
      "www.jeffelmore.org\n",
      "www.lexile.com"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Measure difficulty of books emperically, predict measures using text features\n",
      "\n",
      "MetaMetrics - Lexile Framework for Reading\n",
      "\n",
      "k-2, measure differentiated instruction in reading\n",
      "\n",
      "place readers on same level as text\n",
      "\n",
      "This opens up beginning reading materials.\n",
      "\n",
      "\n",
      "Dataset:\n",
      "- 350 books for K-2\n",
      "- Authentic texts with pictures and formatting\n",
      "- \"Turn no book away\" (even weird ones)\n",
      "\n",
      "Empircal Measures:\n",
      "- Interval, not ordinal, scale (continuous measure of difficulty)\n",
      "- Student Performance\n",
      "- Human judgement\n",
      "- correspondance between what is thought to be difficult by teachers and what readers believe.\n",
      "\n",
      "Psychometric Modeling\n",
      "- Rasch model\n",
      "- Read wikipedia\n",
      "- Assign score to each text from emperical data\n",
      "\n",
      "Study 1: Expert\n",
      "- 350 books\n",
      "- 100 early reading educators\n",
      "- Paired comparisons\n",
      "- ~12000 comparisons total\n",
      "\n",
      "Study 2: Sudent Comprehension\n",
      "- 90 short passages excerpted from same 350 books\n",
      "- \"Maze\" assessment with authentic texts\n",
      "- 20 to 40 multiple choice per package\n",
      "- 1200 1st and 2nd grade readers\n",
      "\n",
      "How similar are results?\n",
      "- R: 0.79\n",
      "\n",
      "Predicting Empirical Meausres\n",
      "- Given text, predict scale score using only text features\n",
      "- Leave out 20% for validation, 80% for training and test\n",
      "\n",
      "Beginning Reading is different\n",
      "- Different cognitave things happen (connect sound to words)\n",
      "- Purpose is different (learn how language works)\n",
      "- Texts have different properties\n",
      "\n",
      "Linguistic Levels\n",
      "- Sounds in words\n",
      "- word structure\n",
      "- word meaning\n",
      "- within-sentence syntax\n",
      "- discourse features\n",
      "\n",
      "Code faster ... do more science\n",
      "- Infinite ways of modelling texts, the more we test the better\n",
      "- Create framework of tunable and composable text feature extractors\n",
      "- Python!\n",
      "\n",
      "Libraries:\n",
      "- scipy, numpy, matplotlib\n",
      "- pandas\n",
      "- scikit-learn\n",
      "- nltk\n",
      "- pylinkgrammar (sentence parsing)\n",
      "- gensim (\"topic modeling for humans\")\n",
      "- python-levenshtein (edit distance calculation, fuzzy string matching)\n",
      "\n",
      "Variable development\n",
      "- Developed 242 unique text features\n",
      "- Many seek to measure same constructs\n",
      "- Performed variable model selection (RandomForrest) and arrived at a 4 variable model\n",
      "\n",
      "Varialbes\n",
      "- Intersentential Complexity\n",
      "- Concept Density\n",
      "- Syllables\n",
      "- Age-of-acquisition\n",
      "\n",
      "Intersentential Complexity\n",
      "- Mean linear edit distance (see gensim)\n",
      "- How hard to change one sentence to another\n",
      "\n",
      "Concept Density\n",
      "- Vector space over text, column is a word\n",
      "- Dimension reduction to see if can explain with fewer words\n",
      "- Compression (Use bzip to see length of final string, not as good)\n",
      "\n",
      "So does it work?\n",
      "- Yes!\n",
      "- R: 0.85\n",
      "- Used leave-one-out cross validation on entire dataset, R: 0.87\n",
      "\n",
      "Look at notebook!\n",
      "- Use pandas!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}